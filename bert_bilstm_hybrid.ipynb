{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-11-07T13:54:00.701890Z","iopub.status.busy":"2024-11-07T13:54:00.701529Z","iopub.status.idle":"2024-11-07T13:54:17.223617Z","shell.execute_reply":"2024-11-07T13:54:17.222562Z","shell.execute_reply.started":"2024-11-07T13:54:00.701858Z"},"id":"oZrgKarjiL4N","outputId":"8ecab4e6-40ce-4c4b-e784-b81ef9dd7127","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (3.0.1)\n","Requirement already satisfied: keras-tuner in /opt/conda/lib/python3.10/site-packages (1.4.7)\n","Collecting contractions\n","  Downloading contractions-0.1.73-py2.py3-none-any.whl.metadata (1.2 kB)\n","Collecting pyspellchecker\n","  Downloading pyspellchecker-0.8.1-py3-none-any.whl.metadata (9.4 kB)\n","Collecting langdetect\n","  Downloading langdetect-1.0.9.tar.gz (981 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hCollecting deep-translator\n","  Downloading deep_translator-1.11.4-py3-none-any.whl.metadata (30 kB)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.15.1)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\n","Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\n","Requirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.32.3)\n","Requirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.4)\n","Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\n","Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n","Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\n","Requirement already satisfied: huggingface-hub>=0.22.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.25.1)\n","Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.2)\n","Requirement already satisfied: keras in /opt/conda/lib/python3.10/site-packages (from keras-tuner) (3.3.3)\n","Requirement already satisfied: kt-legacy in /opt/conda/lib/python3.10/site-packages (from keras-tuner) (1.0.5)\n","Collecting textsearch>=0.0.21 (from contractions)\n","  Downloading textsearch-0.0.24-py2.py3-none-any.whl.metadata (1.2 kB)\n","Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from langdetect) (1.16.0)\n","Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in /opt/conda/lib/python3.10/site-packages (from deep-translator) (4.12.3)\n","Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep-translator) (2.5)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.22.0->datasets) (4.12.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n","Collecting anyascii (from textsearch>=0.0.21->contractions)\n","  Downloading anyascii-0.3.2-py3-none-any.whl.metadata (1.5 kB)\n","Collecting pyahocorasick (from textsearch>=0.0.21->contractions)\n","  Downloading pyahocorasick-2.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (13 kB)\n","Requirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from keras->keras-tuner) (1.4.0)\n","Requirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from keras->keras-tuner) (13.7.1)\n","Requirement already satisfied: namex in /opt/conda/lib/python3.10/site-packages (from keras->keras-tuner) (0.0.8)\n","Requirement already satisfied: h5py in /opt/conda/lib/python3.10/site-packages (from keras->keras-tuner) (3.11.0)\n","Requirement already satisfied: optree in /opt/conda/lib/python3.10/site-packages (from keras->keras-tuner) (0.11.0)\n","Requirement already satisfied: ml-dtypes in /opt/conda/lib/python3.10/site-packages (from keras->keras-tuner) (0.3.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n","Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras->keras-tuner) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras->keras-tuner) (2.18.0)\n","Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n","Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n","Downloading pyspellchecker-0.8.1-py3-none-any.whl (6.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m88.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading deep_translator-1.11.4-py3-none-any.whl (42 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n","Downloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pyahocorasick-2.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (110 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.7/110.7 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: langdetect\n","  Building wheel for langdetect (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993227 sha256=0b9ffbbf318e1272a64e05ef578b0784a8a95c0369a221f681cf8558e430ee0d\n","  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n","Successfully built langdetect\n","Installing collected packages: pyspellchecker, pyahocorasick, langdetect, anyascii, textsearch, deep-translator, contractions\n","Successfully installed anyascii-0.3.2 contractions-0.1.73 deep-translator-1.11.4 langdetect-1.0.9 pyahocorasick-2.1.0 pyspellchecker-0.8.1 textsearch-0.0.24\n"]}],"source":["!pip install datasets keras-tuner contractions pyspellchecker langdetect deep-translator"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-11-07T13:54:17.226507Z","iopub.status.busy":"2024-11-07T13:54:17.226076Z","iopub.status.idle":"2024-11-07T13:54:33.065983Z","shell.execute_reply":"2024-11-07T13:54:33.064996Z","shell.execute_reply.started":"2024-11-07T13:54:17.226445Z"},"id":"ULaU3KqpnzgA","trusted":true},"outputs":[],"source":["import numpy as np\n","\n","import torch\n","\n","import torch.nn as nn\n","\n","from tensorflow.keras.models import Sequential\n","\n","from tensorflow.keras.layers import Dense, Dropout, Embedding, Bidirectional, GRU, Layer, Input, Conv1D, MaxPooling1D, GlobalMaxPooling1D, LSTM, Concatenate, MultiHeadAttention, Add,LayerNormalization, BatchNormalization\n","\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","\n","from keras.preprocessing.sequence import pad_sequences\n","\n","from tensorflow.keras.optimizers import Adam\n","\n","from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n","\n","from datasets import load_dataset\n","\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report, accuracy_score\n","\n","import re\n","\n","import matplotlib.pyplot as plt\n","\n","import tensorflow as tf\n","\n","from tensorflow import keras\n","\n","import keras_tuner as kt\n","\n","from torch.optim import AdamW\n","\n","from torch.optim.lr_scheduler import ReduceLROnPlateau\n","\n","from tqdm import tqdm\n","\n","from transformers import BertTokenizer, BertModel\n","\n","from torch.utils.data import DataLoader\n","\n","from deep_translator import MyMemoryTranslator\n","\n","from langdetect import detect\n","\n","import spacy\n","\n","import contractions\n","\n","import nltk\n","\n","from spellchecker import SpellChecker\n","\n","import random\n","\n","from GPUtil import showUtilization as gpu_usage\n","\n","from numba import cuda\n","\n","from datasets import load_dataset\n","\n","import optuna\n","\n","from tensorflow.keras.models import Model\n","\n","from tensorflow.keras.regularizers import l2\n","\n","from sklearn.linear_model import LogisticRegression\n","\n","# Set a seed value\n","\n","seed_value = 42\n","\n","\n","\n","random.seed(seed_value)\n","\n","# For NumPy\n","\n","np.random.seed(seed_value)\n","\n","\n","\n","# For TensorFlow\n","\n","tf.random.set_seed(seed_value)\n","\n","\n","\n","# For PyTorch\n","\n","torch.manual_seed(seed_value)\n","\n","if torch.cuda.is_available():\n","\n","    torch.cuda.manual_seed(seed_value)\n","\n","    torch.cuda.manual_seed_all(seed_value)  # if using multi-GPU\n","\n","    torch.backends.cudnn.deterministic = True\n","\n","    torch.backends.cudnn.benchmark = False"]},{"cell_type":"markdown","metadata":{},"source":["# Transformer Model (BERT + BiLSTM)"]},{"cell_type":"code","execution_count":52,"metadata":{"execution":{"iopub.execute_input":"2024-11-06T15:50:19.376915Z","iopub.status.busy":"2024-11-06T15:50:19.375806Z","iopub.status.idle":"2024-11-06T15:50:33.931373Z","shell.execute_reply":"2024-11-06T15:50:33.930300Z","shell.execute_reply.started":"2024-11-06T15:50:19.376858Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting GPUtil\n","  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hBuilding wheels for collected packages: GPUtil\n","  Building wheel for GPUtil (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for GPUtil: filename=GPUtil-1.4.0-py3-none-any.whl size=7394 sha256=fce45d05bd5ee4dce50e8a1cc5c8f5d3c62f238ee883bb19c7d29db78c3399fb\n","  Stored in directory: /root/.cache/pip/wheels/a9/8a/bd/81082387151853ab8b6b3ef33426e98f5cbfebc3c397a9d4d0\n","Successfully built GPUtil\n","Installing collected packages: GPUtil\n","Successfully installed GPUtil-1.4.0\n","Initial GPU Usage\n","| ID | GPU | MEM |\n","------------------\n","|  0 |  0% | 99% |\n","GPU Usage after emptying the cache\n","| ID | GPU | MEM |\n","------------------\n","|  0 | 85% |  2% |\n"]}],"source":["def free_gpu_cache():\n","    print(\"Initial GPU Usage\")\n","    gpu_usage()                             \n","\n","    torch.cuda.empty_cache()\n","\n","    cuda.select_device(0)\n","    cuda.close()\n","    cuda.select_device(0)\n","\n","    print(\"GPU Usage after emptying the cache\")\n","    gpu_usage()\n","\n","free_gpu_cache()                           \n"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-11-07T14:02:35.886318Z","iopub.status.busy":"2024-11-07T14:02:35.885300Z","iopub.status.idle":"2024-11-07T14:02:40.261550Z","shell.execute_reply":"2024-11-07T14:02:40.260684Z","shell.execute_reply.started":"2024-11-07T14:02:35.886275Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"44344a0b0a1c46e48b1a11e8c96a60ec","version_major":2,"version_minor":0},"text/plain":["README.md:   0%|          | 0.00/7.46k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cc7b544b4a4a49e5895886c1e8f164b0","version_major":2,"version_minor":0},"text/plain":["train.parquet:   0%|          | 0.00/699k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c8bafff43da74989aea4283e050af570","version_major":2,"version_minor":0},"text/plain":["validation.parquet:   0%|          | 0.00/90.0k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e749826cd39642ce982736427dde8c20","version_major":2,"version_minor":0},"text/plain":["test.parquet:   0%|          | 0.00/92.2k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"affe582259224acbb17985fd0999096f","version_major":2,"version_minor":0},"text/plain":["Generating train split:   0%|          | 0/8530 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9cc9f366f57545008f2eec55183e7b88","version_major":2,"version_minor":0},"text/plain":["Generating validation split:   0%|          | 0/1066 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"866c9c82add44498bf66fbdd298b7ffb","version_major":2,"version_minor":0},"text/plain":["Generating test split:   0%|          | 0/1066 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# Load the Rotten Tomatoes dataset\n","dataset = load_dataset(\"rotten_tomatoes\")\n","\n","# Split the dataset into training, validation, and test sets\n","train_dataset = dataset['train']\n","validation_dataset = dataset['validation']\n","test_dataset = dataset['test']\n"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-11-07T14:17:16.763883Z","iopub.status.busy":"2024-11-07T14:17:16.763240Z","iopub.status.idle":"2024-11-07T14:17:28.908397Z","shell.execute_reply":"2024-11-07T14:17:28.907463Z","shell.execute_reply.started":"2024-11-07T14:17:16.763842Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4cc4fcd628ce48168ea745dd339f4d91","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/8530 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"24a5c41af9a443cbbefd50a4266b0224","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/1066 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"00584dd921484a0b8e04832d170b4a1a","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/1066 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# Initialize BERT tokenizer\n","tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n","\n","# Tokenize the dataset\n","def tokenize_function(example):\n","    return tokenizer(example['text'], padding=\"max_length\", truncation=True, max_length=128)\n","\n","# Apply the tokenizer on the dataset\n","train_dataset = train_dataset.map(tokenize_function, batched=True)\n","validation_dataset = validation_dataset.map(tokenize_function, batched=True)\n","test_dataset = test_dataset.map(tokenize_function, batched=True)\n","\n","# Convert datasets to PyTorch format\n","train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n","validation_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n","test_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n","\n","# DataLoaders\n","batch_size = 128\n","train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n","validation_loader = DataLoader(validation_dataset, batch_size=batch_size)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size)\n"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-11-07T14:55:20.131614Z","iopub.status.busy":"2024-11-07T14:55:20.131196Z","iopub.status.idle":"2024-11-07T14:55:20.140666Z","shell.execute_reply":"2024-11-07T14:55:20.139601Z","shell.execute_reply.started":"2024-11-07T14:55:20.131575Z"},"trusted":true},"outputs":[],"source":["class BertBiLSTM(nn.Module):\n","    def __init__(self, bert_model_name=\"bert-base-uncased\", lstm_hidden_size=128, lstm_layers = 2, num_classes=2, dropout_rate = 0.1):\n","        super(BertBiLSTM, self).__init__()\n","        self.bert = BertModel.from_pretrained(bert_model_name, gradient_checkpointing=True)\n","        self.lstm = nn.LSTM(input_size=self.bert.config.hidden_size,\n","                            hidden_size=lstm_hidden_size,\n","                            num_layers=lstm_layers,\n","                            bidirectional=True,\n","                            batch_first=True)\n","        self.dropout = nn.Dropout(dropout_rate)\n","        self.classifier = nn.Linear(lstm_hidden_size * 2, num_classes)  # BiLSTM is bidirectional\n","\n","    def forward(self, input_ids, attention_mask):\n","        # Get the BERT embeddings\n","        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n","        sequence_output = outputs.last_hidden_state\n","\n","        # Pass BERT embeddings through the BiLSTM\n","        lstm_output, _ = self.lstm(sequence_output)\n","\n","        # Take the output of the LSTM's last time step\n","        lstm_output = lstm_output[:, -1, :]\n","\n","        lstm_output = self.dropout(lstm_output)\n","        \n","        # Classify using a linear layer\n","        logits = self.classifier(lstm_output)\n","\n","        return logits\n"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-11-07T14:34:47.603482Z","iopub.status.busy":"2024-11-07T14:34:47.603091Z","iopub.status.idle":"2024-11-07T14:47:40.871512Z","shell.execute_reply":"2024-11-07T14:47:40.870548Z","shell.execute_reply.started":"2024-11-07T14:34:47.603444Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 67/67 [02:02<00:00,  1.84s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.4912, Training accuracy: 0.8089\n","Validation loss: 0.3716, Validation accuracy: 0.8508\n","Epoch 2/10\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 67/67 [02:04<00:00,  1.85s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.2984, Training accuracy: 0.8971\n","Validation loss: 0.3802, Validation accuracy: 0.8583\n","Epoch 3/10\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 67/67 [02:04<00:00,  1.85s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.2035, Training accuracy: 0.9362\n","Validation loss: 0.3661, Validation accuracy: 0.8602\n","Epoch 4/10\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 67/67 [02:04<00:00,  1.85s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.1487, Training accuracy: 0.9543\n","Validation loss: 0.4169, Validation accuracy: 0.8602\n","Epoch 5/10\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 67/67 [02:04<00:00,  1.85s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.1054, Training accuracy: 0.9719\n","Validation loss: 0.4419, Validation accuracy: 0.8612\n","Epoch 6/10\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 67/67 [02:04<00:00,  1.85s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.0783, Training accuracy: 0.9815\n","Validation loss: 0.4713, Validation accuracy: 0.8612\n","Early stopping triggered.\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_30/715145176.py:88: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model.load_state_dict(torch.load(\"best_model.pth\"))\n"]},{"name":"stdout","output_type":"stream","text":["Test loss: 0.3788, Test accuracy: 0.8462\n"]}],"source":["# Initialize device, model, criterion, optimizer, and scheduler\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = BertBiLSTM(num_classes=2).to(device)\n","criterion = nn.CrossEntropyLoss().to(device)\n","optimizer = AdamW(model.parameters(), lr=2e-5)\n","scheduler = ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.1, patience=2, verbose=True)\n","\n","# Early stopping parameters\n","early_stopping_patience = 3  # stop after 3 epochs with no improvement\n","best_val_loss = float(\"inf\")\n","early_stop_counter = 0\n","\n","# Training function\n","def train(model, dataloader, optimizer, criterion):\n","    model.train()\n","    total_loss, total_correct = 0, 0\n","    for batch in tqdm(dataloader):\n","        input_ids = batch[\"input_ids\"].to(device)\n","        attention_mask = batch[\"attention_mask\"].to(device)\n","        labels = batch[\"label\"].to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","        total_correct += (outputs.argmax(dim=1) == labels).sum().item()\n","\n","    avg_loss = total_loss / len(dataloader)\n","    accuracy = total_correct / len(dataloader.dataset)\n","    return avg_loss, accuracy\n","\n","# Evaluation function\n","def evaluate(model, dataloader, criterion):\n","    model.eval()\n","    total_loss, total_correct = 0, 0\n","    with torch.no_grad():\n","        for batch in dataloader:\n","            input_ids = batch[\"input_ids\"].to(device)\n","            attention_mask = batch[\"attention_mask\"].to(device)\n","            labels = batch[\"label\"].to(device)\n","\n","            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n","            loss = criterion(outputs, labels)\n","\n","            total_loss += loss.item()\n","            total_correct += (outputs.argmax(dim=1) == labels).sum().item()\n","\n","    avg_loss = total_loss / len(dataloader)\n","    accuracy = total_correct / len(dataloader.dataset)\n","    return avg_loss, accuracy\n","\n","# Training loop with early stopping and learning rate scheduler\n","epochs = 10\n","for epoch in range(epochs):\n","    print(f\"Epoch {epoch+1}/{epochs}\")\n","    train_loss, train_accuracy = train(model, train_loader, optimizer, criterion)\n","    val_loss, val_accuracy = evaluate(model, validation_loader, criterion)\n","\n","    # Print training and validation statistics\n","    print(f\"Training loss: {train_loss:.4f}, Training accuracy: {train_accuracy:.4f}\")\n","    print(f\"Validation loss: {val_loss:.4f}, Validation accuracy: {val_accuracy:.4f}\")\n","\n","    # Step with the scheduler\n","    scheduler.step(val_loss)\n","\n","    # Early stopping check\n","    if val_loss < best_val_loss:\n","        best_val_loss = val_loss\n","        early_stop_counter = 0\n","        # Optionally save the best model\n","        torch.save(model.state_dict(), \"best_model.pth\")\n","    else:\n","        early_stop_counter += 1\n","        if early_stop_counter >= early_stopping_patience:\n","            print(\"Early stopping triggered.\")\n","            break\n","\n","# Load the best model (if early stopping saved it)\n","model.load_state_dict(torch.load(\"best_model.pth\"))\n","\n","# Evaluate on the test set\n","test_loss, test_accuracy = evaluate(model, test_loader, criterion)\n","print(f\"Test loss: {test_loss:.4f}, Test accuracy: {test_accuracy:.4f}\")\n"]},{"cell_type":"markdown","metadata":{},"source":["# BERT + BiLSTM hyperparameter tuning"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-11-07T14:55:41.909981Z","iopub.status.busy":"2024-11-07T14:55:41.909584Z","iopub.status.idle":"2024-11-07T18:16:22.146814Z","shell.execute_reply":"2024-11-07T18:16:22.145923Z","shell.execute_reply.started":"2024-11-07T14:55:41.909945Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["[I 2024-11-07 14:55:41,917] A new study created in memory with name: no-name-2a68ef6b-20b5-490e-996f-25afc7b639c3\n","/tmp/ipykernel_30/410620912.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-3)\n","100%|██████████| 67/67 [02:01<00:00,  1.81s/it]\n","100%|██████████| 67/67 [02:02<00:00,  1.83s/it]\n","100%|██████████| 67/67 [02:03<00:00,  1.84s/it]\n","100%|██████████| 67/67 [02:03<00:00,  1.84s/it]\n","100%|██████████| 67/67 [02:03<00:00,  1.84s/it]\n","100%|██████████| 67/67 [02:03<00:00,  1.84s/it]\n","[I 2024-11-07 15:08:22,274] Trial 0 finished with value: 0.38136272960238987 and parameters: {'lstm_hidden_size': 64, 'lstm_layers': 3, 'dropout_rate': 0.5, 'learning_rate': 2.3155015612111282e-05}. Best is trial 0 with value: 0.38136272960238987.\n","100%|██████████| 67/67 [02:03<00:00,  1.84s/it]\n","100%|██████████| 67/67 [02:03<00:00,  1.84s/it]\n","100%|██████████| 67/67 [02:03<00:00,  1.84s/it]\n","100%|██████████| 67/67 [02:03<00:00,  1.84s/it]\n","100%|██████████| 67/67 [02:03<00:00,  1.85s/it]\n","[I 2024-11-07 15:18:58,703] Trial 1 finished with value: 0.69054204887814 and parameters: {'lstm_hidden_size': 128, 'lstm_layers': 1, 'dropout_rate': 0.5, 'learning_rate': 0.0004990775147916834}. Best is trial 0 with value: 0.38136272960238987.\n","100%|██████████| 67/67 [02:02<00:00,  1.83s/it]\n","100%|██████████| 67/67 [02:02<00:00,  1.83s/it]\n","100%|██████████| 67/67 [02:03<00:00,  1.84s/it]\n","100%|██████████| 67/67 [02:02<00:00,  1.84s/it]\n","100%|██████████| 67/67 [02:02<00:00,  1.83s/it]\n","[I 2024-11-07 15:29:32,843] Trial 2 finished with value: 0.34957156744268203 and parameters: {'lstm_hidden_size': 64, 'lstm_layers': 2, 'dropout_rate': 0.4, 'learning_rate': 6.908762718528922e-05}. Best is trial 2 with value: 0.34957156744268203.\n","100%|██████████| 67/67 [02:06<00:00,  1.89s/it]\n","100%|██████████| 67/67 [02:06<00:00,  1.89s/it]\n","100%|██████████| 67/67 [02:06<00:00,  1.89s/it]\n","100%|██████████| 67/67 [02:06<00:00,  1.90s/it]\n","[I 2024-11-07 15:38:17,576] Trial 3 finished with value: 0.3544947819577323 and parameters: {'lstm_hidden_size': 192, 'lstm_layers': 1, 'dropout_rate': 0.1, 'learning_rate': 0.00020416994847952794}. Best is trial 2 with value: 0.34957156744268203.\n","100%|██████████| 67/67 [02:05<00:00,  1.87s/it]\n","100%|██████████| 67/67 [02:04<00:00,  1.86s/it]\n","100%|██████████| 67/67 [02:04<00:00,  1.86s/it]\n","100%|██████████| 67/67 [02:05<00:00,  1.87s/it]\n","[I 2024-11-07 15:46:53,381] Trial 4 finished with value: 0.3368954277700848 and parameters: {'lstm_hidden_size': 256, 'lstm_layers': 1, 'dropout_rate': 0.1, 'learning_rate': 0.00014347431410385842}. Best is trial 4 with value: 0.3368954277700848.\n","100%|██████████| 67/67 [02:02<00:00,  1.83s/it]\n","100%|██████████| 67/67 [02:02<00:00,  1.83s/it]\n","100%|██████████| 67/67 [02:02<00:00,  1.83s/it]\n","100%|██████████| 67/67 [02:02<00:00,  1.83s/it]\n","[I 2024-11-07 15:55:20,170] Trial 5 finished with value: 0.34118495881557465 and parameters: {'lstm_hidden_size': 64, 'lstm_layers': 1, 'dropout_rate': 0.2, 'learning_rate': 2.4744325946489053e-05}. Best is trial 4 with value: 0.3368954277700848.\n","100%|██████████| 67/67 [02:08<00:00,  1.91s/it]\n","100%|██████████| 67/67 [02:08<00:00,  1.92s/it]\n","100%|██████████| 67/67 [02:08<00:00,  1.92s/it]\n","100%|██████████| 67/67 [02:08<00:00,  1.91s/it]\n","[I 2024-11-07 16:04:09,863] Trial 6 finished with value: 0.3193674070967568 and parameters: {'lstm_hidden_size': 256, 'lstm_layers': 2, 'dropout_rate': 0.5, 'learning_rate': 0.00011916060344587308}. Best is trial 6 with value: 0.3193674070967568.\n","100%|██████████| 67/67 [02:07<00:00,  1.90s/it]\n","100%|██████████| 67/67 [02:06<00:00,  1.89s/it]\n","100%|██████████| 67/67 [02:06<00:00,  1.89s/it]\n","100%|██████████| 67/67 [02:06<00:00,  1.90s/it]\n","[I 2024-11-07 16:12:54,765] Trial 7 finished with value: 0.3994982987642288 and parameters: {'lstm_hidden_size': 192, 'lstm_layers': 1, 'dropout_rate': 0.5, 'learning_rate': 0.00012352482742719302}. Best is trial 6 with value: 0.3193674070967568.\n","100%|██████████| 67/67 [02:06<00:00,  1.89s/it]\n","100%|██████████| 67/67 [02:06<00:00,  1.89s/it]\n","100%|██████████| 67/67 [02:06<00:00,  1.89s/it]\n","100%|██████████| 67/67 [02:06<00:00,  1.89s/it]\n","[I 2024-11-07 16:21:39,416] Trial 8 finished with value: 0.3457678043180042 and parameters: {'lstm_hidden_size': 192, 'lstm_layers': 1, 'dropout_rate': 0.30000000000000004, 'learning_rate': 4.696407425709372e-05}. Best is trial 6 with value: 0.3193674070967568.\n","100%|██████████| 67/67 [02:02<00:00,  1.83s/it]\n","100%|██████████| 67/67 [02:02<00:00,  1.83s/it]\n","100%|██████████| 67/67 [02:02<00:00,  1.83s/it]\n","100%|██████████| 67/67 [02:02<00:00,  1.83s/it]\n","100%|██████████| 67/67 [02:02<00:00,  1.83s/it]\n","[I 2024-11-07 16:32:12,853] Trial 9 finished with value: 0.3413265099128087 and parameters: {'lstm_hidden_size': 64, 'lstm_layers': 1, 'dropout_rate': 0.1, 'learning_rate': 1.1533436989515392e-05}. Best is trial 6 with value: 0.3193674070967568.\n","100%|██████████| 67/67 [02:11<00:00,  1.96s/it]\n","100%|██████████| 67/67 [02:11<00:00,  1.96s/it]\n","100%|██████████| 67/67 [02:11<00:00,  1.96s/it]\n","100%|██████████| 67/67 [02:11<00:00,  1.96s/it]\n","100%|██████████| 67/67 [02:11<00:00,  1.96s/it]\n","[I 2024-11-07 16:43:30,571] Trial 10 finished with value: 0.6912784311506484 and parameters: {'lstm_hidden_size': 256, 'lstm_layers': 3, 'dropout_rate': 0.30000000000000004, 'learning_rate': 0.0009691915805646516}. Best is trial 6 with value: 0.3193674070967568.\n","100%|██████████| 67/67 [02:07<00:00,  1.91s/it]\n","100%|██████████| 67/67 [02:07<00:00,  1.91s/it]\n","100%|██████████| 67/67 [02:08<00:00,  1.92s/it]\n","100%|██████████| 67/67 [02:08<00:00,  1.92s/it]\n","100%|██████████| 67/67 [02:08<00:00,  1.91s/it]\n","100%|██████████| 67/67 [02:08<00:00,  1.92s/it]\n","[I 2024-11-07 16:56:44,230] Trial 11 finished with value: 0.4273342986901601 and parameters: {'lstm_hidden_size': 256, 'lstm_layers': 2, 'dropout_rate': 0.2, 'learning_rate': 0.00022070062336165157}. Best is trial 6 with value: 0.3193674070967568.\n","100%|██████████| 67/67 [02:07<00:00,  1.91s/it]\n","100%|██████████| 67/67 [02:08<00:00,  1.91s/it]\n","100%|██████████| 67/67 [02:08<00:00,  1.91s/it]\n","100%|██████████| 67/67 [02:08<00:00,  1.91s/it]\n","[I 2024-11-07 17:05:33,245] Trial 12 finished with value: 0.3632047176361084 and parameters: {'lstm_hidden_size': 256, 'lstm_layers': 2, 'dropout_rate': 0.4, 'learning_rate': 0.0002349681320850602}. Best is trial 6 with value: 0.3193674070967568.\n","100%|██████████| 67/67 [02:08<00:00,  1.91s/it]\n","100%|██████████| 67/67 [02:08<00:00,  1.91s/it]\n","100%|██████████| 67/67 [02:08<00:00,  1.92s/it]\n","100%|██████████| 67/67 [02:08<00:00,  1.91s/it]\n","[I 2024-11-07 17:14:22,660] Trial 13 finished with value: 0.3159616043170293 and parameters: {'lstm_hidden_size': 256, 'lstm_layers': 2, 'dropout_rate': 0.2, 'learning_rate': 0.00010609586394564347}. Best is trial 13 with value: 0.3159616043170293.\n","100%|██████████| 67/67 [02:04<00:00,  1.86s/it]\n","100%|██████████| 67/67 [02:04<00:00,  1.86s/it]\n","100%|██████████| 67/67 [02:04<00:00,  1.86s/it]\n","100%|██████████| 67/67 [02:04<00:00,  1.86s/it]\n","100%|██████████| 67/67 [02:04<00:00,  1.86s/it]\n","[I 2024-11-07 17:25:06,318] Trial 14 finished with value: 0.34491509530279374 and parameters: {'lstm_hidden_size': 128, 'lstm_layers': 2, 'dropout_rate': 0.2, 'learning_rate': 5.922062772231062e-05}. Best is trial 13 with value: 0.3159616043170293.\n","100%|██████████| 67/67 [02:11<00:00,  1.96s/it]\n","100%|██████████| 67/67 [02:11<00:00,  1.96s/it]\n","100%|██████████| 67/67 [02:11<00:00,  1.96s/it]\n","100%|██████████| 67/67 [02:11<00:00,  1.96s/it]\n","100%|██████████| 67/67 [02:11<00:00,  1.96s/it]\n","[I 2024-11-07 17:36:25,591] Trial 15 finished with value: 0.4401937491363949 and parameters: {'lstm_hidden_size': 192, 'lstm_layers': 2, 'dropout_rate': 0.4, 'learning_rate': 0.00032335036474759825}. Best is trial 13 with value: 0.3159616043170293.\n","100%|██████████| 67/67 [02:11<00:00,  1.96s/it]\n","100%|██████████| 67/67 [02:11<00:00,  1.96s/it]\n","100%|██████████| 67/67 [02:11<00:00,  1.96s/it]\n","100%|██████████| 67/67 [02:11<00:00,  1.96s/it]\n","[I 2024-11-07 17:45:27,731] Trial 16 finished with value: 0.336048338148329 and parameters: {'lstm_hidden_size': 256, 'lstm_layers': 3, 'dropout_rate': 0.30000000000000004, 'learning_rate': 9.153431460378068e-05}. Best is trial 13 with value: 0.3159616043170293.\n","100%|██████████| 67/67 [02:08<00:00,  1.92s/it]\n","100%|██████████| 67/67 [02:08<00:00,  1.91s/it]\n","100%|██████████| 67/67 [02:08<00:00,  1.92s/it]\n","100%|██████████| 67/67 [02:08<00:00,  1.92s/it]\n","100%|██████████| 67/67 [02:08<00:00,  1.92s/it]\n","[I 2024-11-07 17:56:30,120] Trial 17 finished with value: 0.3434760338730282 and parameters: {'lstm_hidden_size': 256, 'lstm_layers': 2, 'dropout_rate': 0.2, 'learning_rate': 3.332621650337811e-05}. Best is trial 13 with value: 0.3159616043170293.\n","100%|██████████| 67/67 [02:05<00:00,  1.88s/it]\n","100%|██████████| 67/67 [02:05<00:00,  1.88s/it]\n","100%|██████████| 67/67 [02:05<00:00,  1.88s/it]\n","100%|██████████| 67/67 [02:05<00:00,  1.88s/it]\n","100%|██████████| 67/67 [02:05<00:00,  1.88s/it]\n","[I 2024-11-07 18:07:19,162] Trial 18 finished with value: 0.6921721630626254 and parameters: {'lstm_hidden_size': 128, 'lstm_layers': 3, 'dropout_rate': 0.4, 'learning_rate': 0.00036830300670151494}. Best is trial 13 with value: 0.3159616043170293.\n","100%|██████████| 67/67 [02:11<00:00,  1.96s/it]\n","100%|██████████| 67/67 [02:11<00:00,  1.96s/it]\n","100%|██████████| 67/67 [02:11<00:00,  1.96s/it]\n","100%|██████████| 67/67 [02:11<00:00,  1.96s/it]\n","[I 2024-11-07 18:16:22,141] Trial 19 finished with value: 0.3353651463985443 and parameters: {'lstm_hidden_size': 192, 'lstm_layers': 2, 'dropout_rate': 0.2, 'learning_rate': 0.00010309736908478752}. Best is trial 13 with value: 0.3159616043170293.\n"]},{"name":"stdout","output_type":"stream","text":["Best trial:\n","  Loss: 0.3159616043170293\n","  Params: \n","    lstm_hidden_size: 256\n","    lstm_layers: 2\n","    dropout_rate: 0.2\n","    learning_rate: 0.00010609586394564347\n"]}],"source":["def objective(trial):\n","    # Hyperparameters to test\n","    lstm_hidden_size = trial.suggest_int(\"lstm_hidden_size\", 64, 256, step=64)\n","    lstm_layers = trial.suggest_int(\"lstm_layers\", 1, 3)\n","    dropout_rate = trial.suggest_float(\"dropout_rate\", 0.1, 0.5, step=0.1)\n","    learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-3)\n","\n","    # Initialize model, optimizer, criterion, scheduler\n","    model = BertBiLSTM(num_classes=2, lstm_hidden_size=lstm_hidden_size, lstm_layers=lstm_layers, dropout_rate=dropout_rate).to(device)\n","    criterion = nn.CrossEntropyLoss().to(device)\n","    optimizer = AdamW(model.parameters(), lr=learning_rate)\n","    scheduler = ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.1, patience=2, verbose=True)\n","\n","    # Early stopping parameters\n","    early_stopping_patience = 3\n","    best_val_loss = float(\"inf\")\n","    early_stop_counter = 0\n","\n","    # Training loop for a limited number of epochs for tuning\n","    for epoch in range(10):  \n","        train_loss, train_accuracy = train(model, train_loader, optimizer, criterion)\n","        val_loss, val_accuracy = evaluate(model, validation_loader, criterion)\n","\n","        # Scheduler step and early stopping\n","        scheduler.step(val_loss)\n","        if val_loss < best_val_loss:\n","            best_val_loss = val_loss\n","            early_stop_counter = 0\n","        else:\n","            early_stop_counter += 1\n","            if early_stop_counter >= early_stopping_patience:\n","                break\n","\n","    return best_val_loss\n","\n","# Run the hyperparameter tuning\n","study = optuna.create_study(direction=\"minimize\")\n","study.optimize(objective, n_trials=20)  # Adjust `n_trials` based on how many configurations you want to test\n","\n","# Print best trial results\n","print(\"Best trial:\")\n","trial = study.best_trial\n","print(f\"  Loss: {trial.value}\")\n","print(\"  Params: \")\n","for key, value in trial.params.items():\n","    print(f\"    {key}: {value}\")"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2024-11-07T18:57:00.388660Z","iopub.status.busy":"2024-11-07T18:57:00.388002Z","iopub.status.idle":"2024-11-07T19:03:41.077935Z","shell.execute_reply":"2024-11-07T19:03:41.076892Z","shell.execute_reply.started":"2024-11-07T18:57:00.388608Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 67/67 [02:07<00:00,  1.90s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.4182, Training accuracy: 0.8123\n","Validation loss: 0.3287, Validation accuracy: 0.8565\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 67/67 [02:07<00:00,  1.91s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.1891, Training accuracy: 0.9306\n","Validation loss: 0.3900, Validation accuracy: 0.8574\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 67/67 [02:07<00:00,  1.91s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.0925, Training accuracy: 0.9706\n","Validation loss: 0.4485, Validation accuracy: 0.8583\n","Early stopping triggered.\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_30/3549608279.py:41: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model.load_state_dict(torch.load(\"best_model.pth\"))\n"]},{"name":"stdout","output_type":"stream","text":["Test Loss: 0.3414, Test Accuracy: 0.8518\n"]}],"source":["best_params = trial.params\n","model = BertBiLSTM(\n","    num_classes=2,\n","    lstm_hidden_size=best_params[\"lstm_hidden_size\"],\n","    lstm_layers=best_params[\"lstm_layers\"],\n","    dropout_rate=best_params[\"dropout_rate\"]\n",").to(device)\n","criterion = nn.CrossEntropyLoss().to(device)\n","optimizer = AdamW(model.parameters(), lr=best_params[\"learning_rate\"])\n","scheduler = ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.1, patience=2, verbose=True)\n","\n","# Early stopping parameters\n","early_stopping_patience = 2\n","best_val_loss = float(\"inf\")\n","early_stop_counter = 0\n","\n","epochs = 10\n","for epoch in range(epochs):\n","    train_loss, train_accuracy = train(model, train_loader, optimizer, criterion)\n","    val_loss, val_accuracy = evaluate(model, validation_loader, criterion)\n","    \n","    # Print training and validation statistics\n","    print(f\"Training loss: {train_loss:.4f}, Training accuracy: {train_accuracy:.4f}\")\n","    print(f\"Validation loss: {val_loss:.4f}, Validation accuracy: {val_accuracy:.4f}\")\n","\n","    # Step with the scheduler\n","    scheduler.step(val_loss)\n","\n","    # Early stopping check\n","    if val_loss < best_val_loss:\n","        best_val_loss = val_loss\n","        early_stop_counter = 0\n","        torch.save(model.state_dict(), \"best_model.pth\")\n","    else:\n","        early_stop_counter += 1\n","        if early_stop_counter >= early_stopping_patience:\n","            print(\"Early stopping triggered.\")\n","            break\n","\n","# Load the best model and evaluate on the test set\n","model.load_state_dict(torch.load(\"best_model.pth\"))\n","test_loss, test_accuracy = evaluate(model, test_loader, criterion)\n","print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")"]}],"metadata":{"colab":{"provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30787,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
